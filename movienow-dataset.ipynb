{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MovieNow dataset\n\nThis code extract the CSV files from the MovieNow dataset so you can download it and start working in this project.","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-02T21:10:49.440631Z","iopub.execute_input":"2023-10-02T21:10:49.440990Z","iopub.status.idle":"2023-10-02T21:10:49.793916Z","shell.execute_reply.started":"2023-10-02T21:10:49.440961Z","shell.execute_reply":"2023-10-02T21:10:49.793103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import csv\nimport requests\nfrom io import StringIO\nimport sqlite3","metadata":{"execution":{"iopub.status.busy":"2023-10-02T21:10:49.795225Z","iopub.execute_input":"2023-10-02T21:10:49.795775Z","iopub.status.idle":"2023-10-02T21:10:49.800721Z","shell.execute_reply.started":"2023-10-02T21:10:49.795749Z","shell.execute_reply":"2023-10-02T21:10:49.799721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conn = sqlite3.connect(':memory:')\ncursor = conn.cursor()\nconn.commit()","metadata":{"execution":{"iopub.status.busy":"2023-10-02T21:10:49.795225Z","iopub.execute_input":"2023-10-02T21:10:49.795775Z","iopub.status.idle":"2023-10-02T21:10:49.800721Z","shell.execute_reply.started":"2023-10-02T21:10:49.795749Z","shell.execute_reply":"2023-10-02T21:10:49.799721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create table\ncrear_tabla_sql =\"\"\"CREATE TABLE IF NOT EXISTS movies\n(\n    movie_id INT,\n    title TEXT,\n    genre TEXT,\n    runtime INT,\n    year_of_release INT,\n    renting_price numeric\n);\n\"\"\"\nconn.execute(crear_tabla_sql)\nconn.commit()\n\n# Download and read the CSV file\nurl = \"https://assets.datacamp.com/production/repositories/4068/datasets/3eebf2a145b76fee37357bcd55ac54577c03c805/movies_181127_2.csv\"\nresponse = requests.get(url)\n\n# Save the temporary CSV file \ncsv_filename = \"movies_data.csv\"\nwith open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n    csv_file.write(response.text)\n    \n#Create the CSV reader\ncsv_data = StringIO(response.text)\ncsv_reader = csv.reader(csv_data)\n\n# Ignore the headers from first row\nnext(csv_reader, None)\n\n# Insert data in the table\ninsertar_datos_sql = \"\"\"\nINSERT INTO movies (movie_id, title, genre, runtime, year_of_release, renting_price)\nVALUES (?, ?, ?, ?, ?, ?);\n\"\"\"\n\nfor row in csv_reader:\n    conn.execute(insertar_datos_sql, row)\n\nconn.commit()\n\n#Print some rows to verify the table structure and data\nsql1=\"\"\"SELECT * FROM movies LIMIT 10;\n\"\"\"\nresultado = pd.read_sql_query(sql1, conn)\nprint(resultado)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T21:10:49.801820Z","iopub.execute_input":"2023-10-02T21:10:49.802373Z","iopub.status.idle":"2023-10-02T21:10:49.940564Z","shell.execute_reply.started":"2023-10-02T21:10:49.802348Z","shell.execute_reply":"2023-10-02T21:10:49.939343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Create table\ncrear_tabla_sql =\"\"\"CREATE TABLE IF NOT EXISTS actors\n(\n    actor_id integer,\n    name character varying,\n    year_of_birth integer,\n    nationality character varying,\n    gender character varying\n);\n\"\"\"\nconn.execute(crear_tabla_sql)\nconn.commit()\n\n# Download and read the CSV file\nurl = \"https://assets.datacamp.com/production/repositories/4068/datasets/c67f20fa317e8229eed7586cda8bfce5fc177444/actors_181127_2.csv\"\nresponse = requests.get(url)\n\n# Save the temporary CSV file \ncsv_filename = \"actors_data.csv\"\nwith open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n    csv_file.write(response.text)\n    \n#Create the CSV reader\ncsv_data = StringIO(response.text)\ncsv_reader = csv.reader(csv_data)\n\n# Ignore the headers from first row\nnext(csv_reader, None)\n\n# Insert data in the table\ninsertar_datos_sql = \"\"\"\nINSERT INTO actors (actor_id, name, year_of_birth, nationality, gender)\nVALUES (?, ?, ?, ?, ?);\n\"\"\"\n\nfor row in csv_reader:\n    conn.execute(insertar_datos_sql, row)\n\nconn.commit()\n\n#Print some rows to verify the table structure and data\nsql1=\"\"\"SELECT * FROM actors LIMIT 10;\n\"\"\"\nresultado = pd.read_sql_query(sql1, conn)\nprint(resultado)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T21:15:46.449025Z","iopub.execute_input":"2023-10-02T21:15:46.449400Z","iopub.status.idle":"2023-10-02T21:15:46.915637Z","shell.execute_reply.started":"2023-10-02T21:15:46.449373Z","shell.execute_reply":"2023-10-02T21:15:46.914674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Createtable\ncrear_tabla_sql =\"\"\"CREATE TABLE IF NOT EXISTS actsin\n(\n    actsin_id integer,\n    movie_id integer,\n    actor_id integer\n);\n\"\"\"\nconn.execute(crear_tabla_sql)\nconn.commit()\n\n# Download and read the CSV file\nurl = \"https://assets.datacamp.com/production/repositories/4068/datasets/6efc08575effcc9327c82fea18aaf22dfd61cc27/actsin_181127_2.csv\"\nresponse = requests.get(url)\n\n# Save the temporary CSV file \ncsv_filename = \"actsin_data.csv\"\nwith open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n    csv_file.write(response.text)\n    \n#Create the CSV reader\ncsv_data = StringIO(response.text)\ncsv_reader = csv.reader(csv_data)\n\n# Ignore the headers from first row\nnext(csv_reader, None)\n\n# Insert data in the table\ninsertar_datos_sql = \"\"\"\nINSERT INTO actsin (actsin_id, movie_id, actor_id)\nVALUES (?, ?, ?);\n\"\"\"\n\nfor row in csv_reader:\n    conn.execute(insertar_datos_sql, row)\n\nconn.commit()\n\n#Print some rows to verify the table structure and data\nsql1=\"\"\"SELECT * FROM actsin LIMIT 10;\n\"\"\"\nresultado = pd.read_sql_query(sql1, conn)\nprint(resultado)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T21:18:25.047605Z","iopub.execute_input":"2023-10-02T21:18:25.047976Z","iopub.status.idle":"2023-10-02T21:18:25.123536Z","shell.execute_reply.started":"2023-10-02T21:18:25.047942Z","shell.execute_reply":"2023-10-02T21:18:25.122492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create table\ncrear_tabla_sql =\"\"\"CREATE TABLE IF NOT EXISTS customers\n(\n    customer_id integer,\n    name character varying,\n    country character varying,\n    gender character varying,\n    date_of_birth date,\n    date_account_start date\n);\n\"\"\"\nconn.execute(crear_tabla_sql)\nconn.commit()\n\n# Download and read the CSV file\nurl = \"https://assets.datacamp.com/production/repositories/4068/datasets/4b1767d8e638ab26e62d98517fef297d72260992/customers_181127_2.csv\"\nresponse = requests.get(url)\n\n# Save the temporary CSV file \ncsv_filename = \"customers_data.csv\"\nwith open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n    csv_file.write(response.text)\n    \n#Create the CSV reader\ncsv_data = StringIO(response.text)\ncsv_reader = csv.reader(csv_data)\n\n# Ignore the headers from first row\nnext(csv_reader, None)\n\n# Insert data in the table\ninsertar_datos_sql = \"\"\"\nINSERT INTO customers (customer_id, name, country, gender, date_of_birth, date_account_start)\nVALUES (?, ?, ?, ?, ?, ?);\n\"\"\"\n\nfor row in csv_reader:\n    conn.execute(insertar_datos_sql, row)\n\nconn.commit()\n\n#Print some rows to verify the table structure and data\nsql1=\"\"\"SELECT * FROM customers LIMIT 10;\n\"\"\"\nresultado = pd.read_sql_query(sql1, conn)\nprint(resultado)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T21:20:41.471091Z","iopub.execute_input":"2023-10-02T21:20:41.471504Z","iopub.status.idle":"2023-10-02T21:20:42.621443Z","shell.execute_reply.started":"2023-10-02T21:20:41.471475Z","shell.execute_reply":"2023-10-02T21:20:42.620372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create table\ncrear_tabla_sql =\"\"\"CREATE TABLE IF NOT EXISTS renting\n(\n    renting_id integer,\n    customer_id integer NOT NULL,\n    movie_id integer NOT NULL,\n    rating integer,\n    date_renting date\n);\n\"\"\"\nconn.execute(crear_tabla_sql)\nconn.commit()\n\n# Download and read the CSV file\nurl = \"https://assets.datacamp.com/production/repositories/4068/datasets/d36ed7719976092a9b3387c8a2ac077914c9e1d2/renting_181127_2.csv\"\nresponse = requests.get(url)\n\n# Save the temporary CSV file \ncsv_filename = \"renting_data.csv\"\nwith open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n    csv_file.write(response.text)\n    \n#Create the CSV reader\ncsv_data = StringIO(response.text)\ncsv_reader = csv.reader(csv_data)\n\n# Ignore the headers from first row\nnext(csv_reader, None)\n\n# Insert data in the table\ninsertar_datos_sql = \"\"\"\nINSERT INTO renting (renting_id, customer_id, movie_id, rating, date_renting)\nVALUES (?, ?, ?, ?, ?);\n\"\"\"\n\nfor row in csv_reader:\n    conn.execute(insertar_datos_sql, row)\n\nconn.commit()\n\n#Print some rows to verify the table structure and data\nsql1=\"\"\"SELECT * FROM renting LIMIT 10;\n\"\"\"\nresultado = pd.read_sql_query(sql1, conn)\nprint(resultado)","metadata":{"execution":{"iopub.status.busy":"2023-10-02T21:22:52.651167Z","iopub.execute_input":"2023-10-02T21:22:52.651509Z","iopub.status.idle":"2023-10-02T21:22:53.748231Z","shell.execute_reply.started":"2023-10-02T21:22:52.651484Z","shell.execute_reply":"2023-10-02T21:22:53.746972Z"},"trusted":true},"execution_count":null,"outputs":[]}]}